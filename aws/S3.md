
# S3

- Operations
    - Serverless, no operations needed
- Security
    - User based
        - IAM policies
    - Resource Based
        - Bucket Policies
        - Object Access Control List
        - Bucket Access Control List
    - ACL
    - Encryption
        - SSE-S3
        - SSE-KMS
        - SSE-C
        - client side encryption
        - SSL in transit
- Reliability
    - 有多種類型可選擇, 但可用性都很多 9 就對了. 支援 Cross-Region Replication, CRR
        - S3 Standard
        - S3 IA
        - S3 One Zone IA
        - Glacier
        - 等等
- Performance
    - single object size limit 5TB
- Cost
    - Pay for storage usage
    - infinite storage


# S3 Object

- key 由 prefix && object name 組成
    ```
    s3://Bucket/Folder/Sub_Folder/File.txt
                ^^^^^^^^^^^^^^^^^^^^^^^^^^  key , Full path
                ^^^^^^^^^^^^^^^^^           Prefix
                                    ^^^^^^^^  Object Name
    ```
- Object Value
    - S3 Object Body(Object Size) 最大為 5 TB
    - 但是上傳的時候, 最大僅能 5GB, 超過得使用 *multi-part upload*


# Security

- User based
    - IAM policies
- Resource Based
    - Bucket Policies
    - Object Access Control List
    - Bucket Access Control List
- S3 Inventory 用來協助管理儲存. 用來做 audit & report 關於 replication & encryption status


# Versioning

- Bucket 啟用 Versioning 以後的 delete 操作:
    - 假設原本沒 Versioning, 有個 a.txt, 之後才啟用 versioning:
        ```
        FileName    Type             Version ID
        a.txt       jpg              null
        ```
    - 再次上傳改版後的 a.txt, 則會看到:
        ```
        FileName    Type             Version ID
        a.txt       jpg              1111
        └ a.txt     jpg              null
        ```
    - (同上, again):
        ```
        FileName    Type             Version ID
        a.txt       jpg              2222
        └ a.txt     jpg              1111
        └ a.txt     jpg              null
        ```
    - 然後再把最新版本(2222)的 a.txt 做 delete
        ```
        FileName    Type             Version ID
        a.txt       Delete marker    3333
        └ a.txt     jpg              2222
        └ a.txt     jpg              1111
        └ a.txt     jpg              null
        ```
    - 此時訪問檔案, 真正看到的版本會是 2222
    - 如果要 rollback 到 1111, 則需把 3333 與 2222 做 *permanently delete*
- 尚未啟用 Versioning 以前的 Objects, 啟用 Versioning 以後, 他們版本會是 null
- 啟用 Versioning 以後, 若再 disable Versioning, 則先前版本不會刪除


# Encryption

- Encrypt in-flight (傳送中加密)
    - HTTPS
        - 若使用 SSE-C, 則必須使用 HTTPS
        - 此外, AWS Console 都是使用這個
- Server Side Encryption, SSE
    - 有下列方式來做 S3 Object Encryption
        - SSE-S3  : 使用 AWS 管理的 encryption keys
            - HTTP / HTTPS
            - 上傳時必須告知 header: 
                - `"X-amz-server-side-encryption":"AES256"`
            - S3 便知道要使用該方式加密
            - AES-256
            - 此 key 完全由 AWS 管理
        - SSE-KMS : 使用 AWS KMS 管理的 encryption keys
            - HTTP / HTTPS
            - 自行將 key 托管至 AWS KMS
            - 預設會有 **aws/s3** 這把可以使用 (免錢)
                - 但如果要自行使用其他的 KMS key 則要每月繳錢
            - 上傳時必須告知 header: 
                - `"X-amz-server-side-encryption":"aws:kms"`
        - SSE-C   : 使用自行管理的 encryption keys
            - HTTPS Only, 只能由 AWS CLI / SDK
                - Web Console 上頭沒這選項
            - AWS 以外的地方, 自行管理 keys
            - 每次發送請求時, 都需要把 key 夾帶在 header 裡頭
            - 指定用哪一把 Key 來作加密:
                - `"x-amz-server-side-encryption-aws-kms-key-id":"arn:aws:kms:{Region}:{AccountID}:key/{KeyID}"`
        - Client Side Encryption, CSE
            - 自行先將要上傳的檔案加密後再上傳, ex: **Amazon S3 encryption clients** 提供了此服務
        - DSSE-KMS
            - 2023/06 新增的機制, double encryption based on KMS


# MFA-Delete

AWS S3 有個保護 Object 的機制, 啟用後, 則無法在 AWS Console 刪除 Object

需要驗證 MFA 才能刪除

Bucket 必須先啟用 Versioning

啟用/關閉 MFA-delete (必須要是 root account && Bucket Owner)

- [Configuring MFA delete](https://docs.aws.amazon.com/AmazonS3/latest/userguide/MultiFactorAuthenticationDelete.html)


```bash
#ENABLED=enabled
#ENABLED=disabled
aws s3api put-bucket-versioning \
    --bucket $BUCKET_NAME \
    --versioning-configuration Status=$ENABLED,MFADelete=Enabled \
    --profile $CONFIG_NAME \
    --mfa "$MFA_DEVICE_ARN $MFA_CODE"
# CONFIG_NAME 預設為 default
# MFA_DEVICE_ARN 長得像這樣 「arn:aws:iam::000000000000:mfa/$USER」
```


# Bucket Policy - Encryption

- S3 Bucket 可設定 *Default Encryption*, Server-Side Encryption:
    - Disable
    - Enable (可設定 customer-provided encryption key(SSE-C))
        - Amazon S3 Key(SSE-S3)
            - 如果用這個, 將來 user 上傳 file 
                - 若有 encrypt, 則照 user 使用的方式 store, 
                - 若沒 encrypt, 則依照此設定 encrypt & store
        - AWS Key Management Service key(SSE-KMS)
            - 


# Access Logs

- [Enabling Amazon S3 server access logging](https://docs.aws.amazon.com/AmazonS3/latest/userguide/enable-server-access-logging.html)
    - Bucket 可 Enable *Server access logging*, 需要指定一個目標 Bucket 作爲儲存 log 的位置.
    - 配置完後, 將來的操作, 可能要等上 10+ 分鐘(講師說要等 couple of hours) 才會有 log 寫入
    - Web Console 配置方式 > 要 log 的 Bucket > Properties > Server access logging > Enable > 指定 logging Bucket
- [Server Access Log Format](https://docs.aws.amazon.com/AmazonS3/latest/userguide/LogFormat.html)
    - 則將來任何 access Bucket 的操作, 都會有操作的 logging 被保存下來 (後續可用 Athena 分析)
- IMPORTANT: 不要把 logging bucket 與 monitoring bucket 設為相同
- 備註: API call 也可被記錄在 Cloudtrail


# Bucket Replication (CRR & SRR)

- CRR, Cross Region Replication
    - near real-time
- SRR, Same Region Replication
- 不支援 chained replication
    - 「A -- replicate --> B && B -- replicate --> C」沒這東西 
- 若要啟用的話, 需要在 Source && Destionation Bucket 皆啟用 Versioning
- 可額外 Enable *Delete Marker Replication*, 則可對 Source 刪除的物件, Replicate 它的 Delete Marker 到 Destionation Bucket
    - 如果沒這麼做的話, Destionation 依舊會存在著 Source 早已刪除掉的 Object


# S3 Pre-Signed URLs

- 可用來產生 供 Download/Access 的 URL(by CLI / AWS Console)
    - 預設為 3600s
    - 可用 `--expires-in [TIME_BY_SECONDS]` 變更 timeout
- 用來產生 供 Upload 的 URL(by SDK)
- Use case
    - 特定期間有效的 URL (ex: 1 hr 後到期)
- 這個和 [CloudFront Signed URL](./cert-SAA_C02.md#cloudfront-cdn) 很容易搞混


# Storage Class

- Durability & Availability
    - Durability   : ex: 99.999999999% (11 9's), 表示儲存在 S3 1000w 個 objects, 放個 10000 years, 會有一個壞掉
        - 各種 Storage Classes Durability 皆為 11 9's
        - 每 100000 年, 1000w 個 objects 平均會壞 N 個, 此為 Durability
    - Availability : ex: 99.99%, 表示一年大概有 53 mins 為 not vaailable
        - 每一年會有 N 分鐘無法使用, 此為 Availability
- 分為下列各種儲存類別. 僅 Standard 存取資料為 Free, 其餘會 Charge
    - Standard-General Purpose
        - Availability: 99.99%
        - Sustain 2 concurrent facility failures
    - Standard-Infrequent Access, IA
        - Availability: 99.9%
        - 相較 General Purpose 便宜, 但是取得資料較慢一點
        - Use Case: Disaster Recovery
    - One Zone-Infrequent Access
        - 如果 AZ 毀了資料也跟著毀了
        - Availability: 99.5%
        - Use Case: Secondary backup
    - S3 Glacier Storage Class
        - Charge: storage + retrive
        - S3 Glacier Instant Retrieval
            - 最少需要保存 90 days
            - 存取速度同 Standard
        - S3 Glacier Flexible Retrieval (一般稱 S3 Glacier)
            - 最少須保存 90 days
            - 有三種 flexibility
                - Expedited (取資料 1~5 mins)
                - Standard  (取資料 3~5 hrs)
                - Bulk      (取資料 5~12 hrs)
        - S3 Glacier Deep Archive
            - 最少須保存 180 days
            - 有兩種 flexibility
                - Standard  (取資料 12 hrs)
                - Bulk      (取資料 48 hrs)
    - Intelligent Tiering
        - Charge: monthly monitoring + auto-tiering fee
            - No retrive Fee
        - AWS 會自動協助變更 S3 Class
            - 會產生 monthly monitoring && auto-tiering fee
- 除了 *Glacier Deep Archive* 與 *Glacier Deep Archive* 以外, 其餘儲存類別的存取速度都是 milliseconds
- [Performance across the S3 Storage Classes](https://aws.amazon.com/s3/storage-classes/?nc1=h_ls)
- [Comparing the Amazon S3 storage classes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html#sc-compare)
- S3 Storage Classes 之間的 transition 的可行方式如下圖:
    - ![S3 Moving Storage Classes](./img/S3_transition_between_StorageClasses.png)


# S3 Life Cycle Rules

- 可藉由此配置, 來設定一系列規則, 讓 AWS 依照這些規則來協助調整 Storage Class
    - Transition actions - 不同 Storage Class 之間的轉換規則
    - Expiration actions - 過一段時間以後, Delete Object. 也可用來刪除 Old Versioning
- 而上述的這些, 可設定 Rules, ex: `s3://mybucket/mp3/*`. 看要套用 Bucket 內的哪些 Objects
- Use Case:
    - 用戶上傳圖片, 程序會製作縮圖, 分別將 src img 及 thumbnail 做儲存(需 45 天內可隨時取得)
        - 將 src img 存入 Standard General Purpose, 搭配 life cycle, 45 天後, 移至 Glacier
        - 將 thumbnail 存入 One-Zone IA(可隨時取得 && 若壞了可隨時由 src img 還原), life cycle 則 45 天後移除
    - 對於 15 天內已移除的資料, 能被隨時還原(即使很少發生), 此外 365 天內移除的資料, 也可在 48 hrs 還原 
        - 需啟用 S3 Versioning, 來確保資料移除後可被還原
        - 因而移除後的 Versioning, 會被 Delete Marker 給遮蔽 (也可輕易地被還原)
        - 而 non-current Versions, 則可放入 Standard IA(省成本 && 需求有提到較少發生)
        - 再搭配 life cycle, 15 天後將 non-current versions 移入 Deep Archive
- 除了自行配置 Life Cycle Rules 以外, 也可使用 **S3 Analytics**, 來讓 AWS 幫忙決定 Storage Class 該如何自動配置
    - 透過機器學習
    - 不適用 *One-Zone IA* && *Glacier*, 僅適用 *Standard* && *Standard IA*
    - 起碼需讓他運行個 24 - 48 hrs, 才能開始運作
- 關於使用 S3 的 [Transitioning objects using Amazon S3 Lifecycle](https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-transition-general-considerations.html)
    - 裏頭有說明各種 Storage Classes 的支援 && 限制(Object Size, 轉換期間的 LifeCycle)


# S3 - Baseline Performance (S3 效能及限制)

- `S3 請求限制(Request limits)`
    - GET/HEAD, 5500/sec
    - PUT/COPY/POST/DELETE, 3500/sec
    - AWS 對於 API call 有軟性限制, ex:
        - EC2 DescribeInstances API, 100次/sec
        - S3 GetObject API, 5500次/sec
    - 如果收到 5XX && `ThrottlingException`, 就表示遇到 `API Rate Limit` 了
        - 如果 code 裡頭有 retry 機制, 會被帶入 *Exponential Backoff*
            - 因此 retry 需要使用 *Exponential Backoff Strategy*
            - 遇到此情況, 1 sec 內無法重複請求, 若再次遇到, 則需等 2 sec, 若再次則 4 sec, 再來 8 sec, 16 sec, ...
        - 如果遇到 4XX 就不要再為難 Server 了, 好好檢討自己吧XD
    - 解法: request an API throttling limit increase
- `S3 - KMS 請求限制(Request limits)`
    - 如果有啟用 KMS, 則可能會遇到 KMS limits 的限制, 導致 S3 吞吐量下滑
        - 無論是 Upload/Download Object <-> S3, 使用到 KMS Key, 都會呼叫到與此對應的 API 來作加解密
        - 此 API 會有訪問限額(不同 Region 不相同), 但可藉由 **Service Quotas Console** 調整此限額
- 大量碎檔
    - `aws configure set default.s3.max_concurrent_requests 100`
- 上傳
    - `Multi-Part upload`
        - 針對特大物件(>5GB), 一定得用這個來上傳 
        - 建議 > 100MB, 就用這個來做上傳
    - `S3 Transfer Acceleration`
        - 可借助 `Edge Location` 來加速上傳 (再走 AWS private 到 S3)
        - 傳輸時, 建議搭配 `Multi-Part upload` 來加速上傳
        - 容易與 [AWS Global Accelerator](./cert-SAA_C02.md#global-accelerator) 搞混
- 下載/查看
    - `S3 Byte-Range Fetches`
        - S3 加速 GET Request -> **S3 Byte-Range Fetches**
        - parallelize GET by requesting 特定的 byte ranges (可只用來取特定 partial data), ex: 
            - 要從非常龐大的 Bucket 分析 metadata, 一定得好好善用這個. 可用來快速取得 first N bytes of object
    - `S3 Select` && `S3 Clacier Select`
        - Server Side Filtering by SQL (Server Filter 來減少傳輸量)
        - 減少 Client Side CPU && Networking
        - 可針對 檔案特定欄位 做 select
        - 只能做簡單 Query, 不支援 aggregation (若要使用, 請用 Athena)


# S3 Website

- S3 託管靜態網頁, 需做底下作業:
    - Bucket 改為 Public Access
    - 制定 Bucket Policy > allow GetObject
        - https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteAccessPermissionsReqd.html
    - enable *Static website hosting*, 填寫 index.html 等
- WebSite URL : 
    - `http://${BUCKET_NAME}.s3-website.${AWS_REGION}.amazonaws.com` 
    - 或 (website. 改成 website-)
    - `http://${BUCKET_NAME}.s3-website-${AWS_REGION}.amazonaws.com`


# S3 Cross-Origin Resource Sharing, CORS

- 若要允許跨站請求, Target Bucket 需 Allow CORS
    - 需要配置 CORS Policy, 參考 [CORS configuration](https://docs.aws.amazon.com/AmazonS3/latest/userguide/ManageCorsUsing.html)
- 用戶要做跨站(cross.com) 請求時, 會有底下動作:
    - Browser 先對 Cross Origin Site 發一個 Preflight Request
        ```
        OPTIONS /
        Host: cross.com
        Origin: https://origin.com
        ```
    - 之後拿到 Cross Site 的 Response
        ```
        Access-Control-Allow-Origin: https://origin.com
        Access-Control-Allow-Methods: GET, PUT, DELETE
        ```
    - Browser 分析後得知有權限訪問後再次發出 Request
        ```
        GET /
        Host: cross.com
        Origin: https://origin.com
        ```
- 而 S3 要允許別人 Cross Site Access 的一方, 需完成底下作業才行:
    - Enable CORS
    - 配置 [CORS configuration](https://docs.aws.amazon.com/AmazonS3/latest/userguide/ManageCorsUsing.html)


# S3 Event Notifications

- S3 Console > Buckets > BUCKET > Properties > Event Notifications
- 可針對 S3 的 Events 設定後續動作, ex: Upload, Delete, ...
- 關於 S3 的相關 Events 的後續動作, 可在 S3 Console 設定 Destination:
    - Lambda
    - SNS
    - SQS
- S3 Console > Buckets > BUCKET > Properties > Amazon EventBridge
    - 可 pipeline 到數十種的 AWS Resources 做後續處理


# S3 Requester pays

- S3 會針對請求的流量對 S3 擁有者計費, 但也可設定讓資源請求者來付費
    - 因此, 資源的請求者, 必須是 AWS Account (無法為 anonymous)


# 關於 S3 及 Glacier 的永久保存機制

- 目的: 用來保護 S3 Object 避免被刪除
    - 可用來因應 company compliance. 限制資料必須 永久保存 OR 保存多久.
    - 有底下的機制:
        - S3 Object Lock
            - create Bucket 的時候, enable Object Lock
                - 此 Bucket 就無法被刪除了
                - Bucket 會自動啟用 versioning
                - 此會套用 WORM(Write Once Read Many) model
                - Policy 一旦制定以後, 連同 Object && Polciy, 都無法被 刪改 (即使是 root/admin 也無法更動)
        - Glacier Vault Lock
            - 針對 S3 Glacier 設定此保護機制, 裡頭的東西無法被任何人刪除 (除非砍帳號)
            - 一旦設定了以後, 就拔不掉了!!!
        - Legal Hold
            - 無期限的保留 S3 Object
            - 一旦 S3 Object 設定了 Legal Hold, 則會無視 S3 Bucket 已經設定好的 Retention Period
            - IAM 如果具備了 `s3:PutObjectLegalHold` 權限的話, 則可 GET/PUT/DELETE object
            - 此機制並不會像 **Vault Lock** 或是 **S3 Object Lock - Compliance mode** 那麼的強制
- 因應各種原因 - Retention Period
    - 若要刪除 Version, 無法即刻刪除(會被 block 一段時間)
    - 一旦 單一 Object 或 all Bucket 啟用了 *retention period*, 會將之紀錄在 Object version's metadata: `Retain Until Date`
        - 直到 Object expires
- S3 Object Lock, 對於 Object 的防護模式, 區分成
    - Governance mode
        - 權限足夠的人 可以 刪除/修改
    - Compliance mode
        - 權限足夠的人 無法 刪除/修改
        - 一旦設定了以後, 就拔不掉了!!!


# S3 - Access Points

- 用來簡化 S3 Bucket Policy 的管理 (假如 S3 裡頭東西很多, 訪問的受眾分類也很廣泛)
- 可針對 Bucket 底下的 Prefix (例如: `/sales/`, `/finance/`) 設定 Access Point, 將之授權給特定人訪問(Read / Write)
    - 每個 **Access Point** 都有它自己的 **Access Point Policy** (等同於 **IAM Policy**)
- 每個 Access Point 都有他們自己的 DNS Name
- 可將 Access Point 設定為, 只允許由 VPC 內部訪問, 此時需要建立 **VPC endpoint**
- 202309 的現在, 無法在 AWS Console 上頭設定 「 藉由 **VPC access point** 訪問 S3 」
    - 需使用 CLI, SDK, API 設定
- 如果來自 global client 要訪問 S3, 可使用 **S3 Multi-Region Access Points** 選擇最低 latency 訪問 S3
    - S3 Bucket 背後會做 **Bi-directional Cross-Region Replication**
    - S3 Multi-Region Access Points 操作方式:
        - 進入 S3 Console, 先建立 N 個不同 Region 的 S3 Buckets
        - (左)Multi-Region Access Points > Create
        - 需要等待 30 mins ~ 24 hrs 等它建立完畢
        - > Create replication rules
    - S3 Multi-Region Access Points - 針對用量計費

---

```mermaid
flowchart LR

ep["VPC Endpoint \n (policy)"]
ap["Access Point \n VPC Origin"]
pap["Public Access Point"]

subgraph VPC
    EC2 --> ep;
end

ep -- "private" --> ap --> S3
public -- internet --> pap;
pap --> S3;
```

- 上圖的 **VPC Endpoint**, 會有它的 **Endpoint Policy**, 需要授權訪問
    - Access Point VPC Origin
    - S3 Bucket
- 上圖的 **Access Point**, 會有 **Access Point Policy**
- 上圖的 **S3 Bucket**, 也會有 **Bucket Policy**

---
